<!DOCTYPE html>
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title></title>
	<style type="text/css">.caption {
            font-style: italic;
            text-align: center;
        }

        .ImgMain {
            max-width: 75%;
            max-height: 75%;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
	</style>
</head>
<body>
<h1 style="text-align:center;">CS445 Proj 4: Image-Base Lighting</h1>

<p class="caption">By Andrew Zhang (alz2) and Utkarsh Awasthi (uawasth2)</p>

<p class="caption">This is a duplicate page. It is hosted on BOTH <a href="http://alz2.web.illinois.edu/cs445/proj4/">Andrew&#39;s</a> and <a href="http://uawasth2.web.illinois.edu/cs445/proj4/">Utkarsh&#39;s</a> project pages.</p>

<hr />
<h2>LDR Merging Techniques</h2>

<h3>Naive</h3>

<p><img class="ImgMain" src="/cs445/proj4/static/naive_irradiances.png" /></p>

<p class="caption">Log irradiances for naive LDR Merging</p>

<p><img class="ImgMain" src="/cs445/proj4/static/naive_merged.png" /></p>

<p class="caption">Tone mapped LDR</p>

<p><img class="ImgMain" src="/cs445/proj4/static/naive_linear_merged.png" /></p>

<p class="caption">Linearly scaled LDR</p>

<h3>Filtered</h3>

<p><img class="ImgMain" src="/cs445/proj4/static/filtered_irradiances.png" /></p>

<p class="caption">Log irradiances for LDR Merging filtering out over and underexposed pixels</p>

<p><img class="ImgMain" src="/cs445/proj4/static/filtered_merged.png" /></p>

<p class="caption">Tone mapped LDR</p>

<p><img class="ImgMain" src="/cs445/proj4/static/filtered_linear_merged.png" /></p>

<p class="caption">Linearly scaled LDR</p>

<h3>Estimating Response Function</h3>

<p><img class="ImgMain" src="/cs445/proj4/static/estimated_irradiances.png" /></p>

<p class="caption">Log irradiances for estimated LDR Merging</p>

<p><img class="ImgMain" src="/cs445/proj4/static/estimated_merged.png" /></p>

<p class="caption">Tone mapped LDR</p>

<p><img class="ImgMain" src="/cs445/proj4/static/estimated_linear_merged.png" /></p>

<p class="caption">Linearly scaled LDR</p>

<p><img class="ImgMain" src="/cs445/proj4/static/g_function.png" /></p>

<h3>Discussion about log irradiances</h3>

<p>The log irradiances of the stages should be different across each stage, but should be more similar between the naive and filtered stage than with the estimated stage.</p>

<p>We know that g(Z) = ln(t) + ln(R), where Z is the pixel intensities, t is the shutter times, and R is the irradiance. For each of the three stages, ln(t) is constant. For the sake of argument, we can ignore ln(t) for explaining how ln(R) is different.</p>

<p>We know ln(R) is different between the estimated stage and both naive and filtered stages because the naive and filtered stages assume that ln(Z) = g(Z) which isn&#39;t the case. g(Z) is actually some camera specific mapping of pixel intensities to log exposures. Thus we can reason that the log irradiance of the estimated stage should be different than both the naive and filtered stages.</p>

<p>We know that log irradiances for the naive and filtered stages should be different because even though they both assume that ln(Z) = g(Z), the pixel intensities of both images are different -- that is, the merged Z&#39;s are different. However, the filtered Z&#39;s are only different in because the filtering process ignores pixels which are over and under exposed, whereas the naive process does no filtering at all. However, given a well taken picture where there are no over and underexposed pixels, the log irradiance should be the same. So because each of the naive and filtered merged Z&#39;s are different, we can reason that ln(R) is different between the naive and filtered stages.</p>

<h2>Panoramic Transformations</h2>

<p style="text-align: center;"><img alt="" src="/cs445/proj4/static/normals.png" style="width: 400px; height: 400px;" /><img alt="" src="/cs445/proj4/static/reflections.png" style="width: 400px; height: 400px;" /><img alt="" src="/cs445/proj4/static/phi_theta_ball.png" style="width: 400px; height: 400px;" /></p>

<p style="text-align: center;">Left to Right:</p>

<p style="text-align: center;">Normals, Reflection Vectors, Reflection Vectors in Spherical Coordinates (Phi and Theta)</p>

<p style="text-align: center;"><img alt="" src="/cs445/proj4/static/equirectangular_transformed.png" style="width: 800px; height: 415px;" /></p>

<p style="text-align: center;">The Equirectangular HDR Image</p>

<p>To Implement the domain transformation, we used the tactics that were suggested by the Project Page as well as Piazza Posts @252 and @301. We first converted the cropped ball to a sphere of normal vectors and then used that to compute our reflection vector sphere. We had X increasing as you went to the right and Y increasing as you went down. Then we converted every reflection vector into the spherical coordinate version using the transforms that I found online on wikipedia, on post @301, and with some additional mat we got the above Equirectangular HDR Image.</p>

<p></p>

<div style="display: flex; justify-content: space-between;"><img src="/cs445/proj4/static/table_normal.jpg" style="max-width:33%; max-height:400px" /> <img src="/cs445/proj4/static/1over100_exp_ball.jpg" style="max-width:33%; max-height:400px" /> <img src="/cs445/proj4/static/merged.png" style="max-width:33%; max-height:400px" /></div>

<p class="caption">Above: Empty photo, photo with light probe, and resulting render.</p>

<div style="display: flex; justify-content: space-between;"><img src="/cs445/proj4/static/3objects.png" style="max-width:33%; max-height:400px" /> <img src="/cs445/proj4/static/3objects_empty.png" style="max-width:33%; max-height:400px" /> <img src="/cs445/proj4/static/3objects_mask.png" style="max-width:33%; max-height:400px" /></div>

<p class="caption">Intermediate processes</p>
</body>
</html>
